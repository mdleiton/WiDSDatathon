{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "import pandas\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preprocesamiento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# modelos\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#guardar modelos\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#evaluacion\n",
    "from sklearn.metrics import *\n",
    "path= \"dataRegularizada/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez preprocesado el dataset se debe ejecutar Training_Test_Data.py para crear 10 datasets para entrenamientos y test de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds  = []\n",
    "test_folds = []\n",
    "for i in range(10):\n",
    "    train = pandas.read_csv(path + \"train_\"+ str(i) + \".csv\", decimal=\".\")\n",
    "    col_mask=train.isnull().any(axis=0) \n",
    "    row_mask=train.isnull().any(axis=1)\n",
    "    train_folds.append(train.loc[-row_mask,-col_mask])\n",
    "    test = pandas.read_csv(path + \"test_\"+ str(i) + \".csv\", decimal=\".\")\n",
    "    col_mask=test.isnull().any(axis=0) \n",
    "    row_mask=test.isnull().any(axis=1)\n",
    "    test_folds.append(test.loc[-row_mask,-col_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>creatinine_apache</th>\n",
       "      <th>hematocrit_apache</th>\n",
       "      <th>map_apache</th>\n",
       "      <th>sodium_apache</th>\n",
       "      <th>temp_apache</th>\n",
       "      <th>wbc_apache</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>18.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>36.700000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>37.00</td>\n",
       "      <td>17.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.70</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>137.0</td>\n",
       "      <td>36.39</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.19</td>\n",
       "      <td>34.700000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>9.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>2.10</td>\n",
       "      <td>37.400000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>36.20</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62.309516</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>137.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>13.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>15.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>37.20</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>42.700000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>36.67</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>39.70</td>\n",
       "      <td>11.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>137.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>62.309516</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>88.015873</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39.60</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>36.20</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.62</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>11.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>35.200000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>18.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.77</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>8.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.10</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.59</td>\n",
       "      <td>39.700000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>35.90</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.30</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>131.0</td>\n",
       "      <td>34.44</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>40.100000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>133.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82511</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>88.015873</td>\n",
       "      <td>138.0</td>\n",
       "      <td>37.70</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82512</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>5.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82513</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.28</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82514</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.18</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>147.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82515</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>36.10</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82516</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>10.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82517</th>\n",
       "      <td>62.309516</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>88.015873</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82518</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82519</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82520</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82521</th>\n",
       "      <td>62.309516</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>88.015873</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82522</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>36.70</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82523</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>36.20</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82524</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.30</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>7.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82525</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>37.10</td>\n",
       "      <td>24.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82526</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>13.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82527</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.10</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>88.015873</td>\n",
       "      <td>141.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82528</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.60</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>146.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82529</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.20</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82530</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>36.30</td>\n",
       "      <td>9.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82531</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.40</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>15.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82532</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>7.10</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>36.80</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82533</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>36.40</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82534</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82535</th>\n",
       "      <td>62.309516</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>88.015873</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82536</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.60</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82537</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>2.30</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>37.40</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82538</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.30</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>35.80</td>\n",
       "      <td>17.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82539</th>\n",
       "      <td>62.309516</td>\n",
       "      <td>0.98</td>\n",
       "      <td>32.988739</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>36.30</td>\n",
       "      <td>10.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82540</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82541 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  creatinine_apache  hematocrit_apache  map_apache  \\\n",
       "0      62.000000               0.70          27.200000  146.000000   \n",
       "1      63.000000               0.98          32.988739   43.000000   \n",
       "2      35.000000               0.40          36.700000  122.000000   \n",
       "3      22.000000               0.98          32.988739  107.000000   \n",
       "4      80.000000               1.70          29.900000  200.000000   \n",
       "5      59.000000               0.30          34.900000   63.000000   \n",
       "6      71.000000               0.98          32.988739  114.000000   \n",
       "7      50.000000               1.19          34.700000  120.000000   \n",
       "8      34.000000               2.10          37.400000   53.000000   \n",
       "9      62.309516               0.98          32.988739   54.000000   \n",
       "10     19.000000               0.67          28.600000   73.000000   \n",
       "11     82.000000               0.98          40.200000  139.000000   \n",
       "12     68.000000               0.98          27.800000   56.000000   \n",
       "13     84.000000               0.98          32.988739  119.000000   \n",
       "14     84.000000               0.90          42.700000  142.000000   \n",
       "15     29.000000               0.60          39.500000   40.000000   \n",
       "16     75.000000               0.60          29.000000  144.000000   \n",
       "17     87.000000               0.80          32.900000  125.000000   \n",
       "18     62.309516               0.98          32.988739   88.015873   \n",
       "19     60.000000               0.70          32.988739  140.000000   \n",
       "20     23.000000               0.80          32.988739  114.000000   \n",
       "21     38.000000               0.70          32.900000  128.000000   \n",
       "22     89.000000               1.62          28.500000   40.000000   \n",
       "23     50.000000               0.80          44.000000  169.000000   \n",
       "24     62.000000               2.00          35.200000   46.000000   \n",
       "25     26.000000               0.77          37.000000   41.000000   \n",
       "26     51.000000               1.10          26.300000   41.000000   \n",
       "27     65.000000               1.59          39.700000   61.000000   \n",
       "28     66.000000               1.30          23.300000   69.000000   \n",
       "29     60.000000               0.93          40.100000  111.000000   \n",
       "...          ...                ...                ...         ...   \n",
       "82511  75.000000               0.98          32.988739   88.015873   \n",
       "82512  19.000000               0.98          35.000000   68.000000   \n",
       "82513  58.000000               1.28          25.600000  151.000000   \n",
       "82514  86.000000               1.18          32.200000  125.000000   \n",
       "82515  71.000000               0.90          32.988739   54.000000   \n",
       "82516  49.000000               0.70          37.000000   71.000000   \n",
       "82517  62.309516               0.98          32.988739   88.015873   \n",
       "82518  83.000000               0.90          32.988739   57.000000   \n",
       "82519  59.000000               0.98          32.988739   41.000000   \n",
       "82520  36.000000               0.40          37.000000   71.000000   \n",
       "82521  62.309516               0.98          32.988739   88.015873   \n",
       "82522  58.000000               1.00          32.988739   62.000000   \n",
       "82523  49.000000               0.70          32.988739  115.000000   \n",
       "82524  65.000000               1.30          32.000000  141.000000   \n",
       "82525  33.000000               0.98          26.000000   49.000000   \n",
       "82526  47.000000               0.50          41.000000   66.000000   \n",
       "82527  57.000000               1.10          37.000000   88.015873   \n",
       "82528  85.000000               1.60          22.000000   40.000000   \n",
       "82529  21.000000               1.20          32.988739   60.000000   \n",
       "82530  18.000000               0.70          41.000000   55.000000   \n",
       "82531  53.000000               1.40          36.000000  133.000000   \n",
       "82532  38.000000               7.10          35.000000   94.000000   \n",
       "82533  67.000000               0.80          32.988739   54.000000   \n",
       "82534  54.000000               0.70          41.000000   62.000000   \n",
       "82535  62.309516               0.98          32.988739   88.015873   \n",
       "82536  75.000000               0.98          32.988739   48.000000   \n",
       "82537  56.000000               2.30          33.000000   62.000000   \n",
       "82538  48.000000               2.30          36.000000   57.000000   \n",
       "82539  62.309516               0.98          32.988739   54.000000   \n",
       "82540  82.000000               1.50          36.000000   56.000000   \n",
       "\n",
       "       sodium_apache  temp_apache  wbc_apache  aids  cirrhosis  \\\n",
       "0              136.0        38.90       18.40   0.0        0.0   \n",
       "1              138.0        36.90       10.40   0.0        0.0   \n",
       "2              132.0        37.00       17.20   0.0        0.0   \n",
       "3              138.0        36.33       10.40   0.0        0.0   \n",
       "4              153.0        36.40       14.20   0.0        0.0   \n",
       "5              137.0        36.39        9.00   0.0        0.0   \n",
       "6              138.0        36.60       10.40   0.0        0.0   \n",
       "7              135.0        39.10        9.89   0.0        0.0   \n",
       "8              128.0        36.20        7.00   0.0        0.0   \n",
       "9              138.0        36.50       10.40   0.0        0.0   \n",
       "10             137.0        36.40       13.24   0.0        0.0   \n",
       "11             138.0        36.50       12.30   0.0        0.0   \n",
       "12             136.0        36.80       15.40   0.0        0.0   \n",
       "13             138.0        37.20       10.40   0.0        0.0   \n",
       "14             139.0        36.67        6.40   0.0        0.0   \n",
       "15             148.0        39.70       11.30   0.0        0.0   \n",
       "16             137.0        36.50        4.70   0.0        0.0   \n",
       "17             144.0        36.80        8.90   0.0        0.0   \n",
       "18             138.0        36.50       10.40   0.0        0.0   \n",
       "19             152.0        39.60       10.40   0.0        0.0   \n",
       "20             141.0        36.20       10.40   0.0        0.0   \n",
       "21             138.0        36.80        8.00   0.0        0.0   \n",
       "22             131.0        36.80       11.23   0.0        0.0   \n",
       "23             136.0        36.80        7.80   0.0        0.0   \n",
       "24             128.0        39.10       18.20   0.0        0.0   \n",
       "25             138.0        36.70        8.63   0.0        0.0   \n",
       "26             132.0        36.60       23.00   0.0        0.0   \n",
       "27             138.0        35.90        7.80   0.0        0.0   \n",
       "28             131.0        34.44        5.80   0.0        0.0   \n",
       "29             133.0        36.70       11.00   0.0        0.0   \n",
       "...              ...          ...         ...   ...        ...   \n",
       "82511          138.0        37.70       10.40   0.0        0.0   \n",
       "82512          138.0        36.60        5.07   0.0        0.0   \n",
       "82513          130.0        36.60        6.50   0.0        0.0   \n",
       "82514          147.0        36.70       20.70   0.0        0.0   \n",
       "82515          139.0        36.10       10.40   0.0        0.0   \n",
       "82516          135.0        36.60       10.73   0.0        0.0   \n",
       "82517          138.0        36.50       10.40   0.0        0.0   \n",
       "82518          144.0        36.70       10.40   0.0        0.0   \n",
       "82519          138.0        36.50       10.40   0.0        0.0   \n",
       "82520          136.0        36.80        5.26   0.0        0.0   \n",
       "82521          138.0        36.50       10.40   0.0        0.0   \n",
       "82522          140.0        36.70       10.40   0.0        0.0   \n",
       "82523          139.0        36.20       10.40   0.0        0.0   \n",
       "82524          138.0        36.80        7.11   0.0        0.0   \n",
       "82525          138.0        37.10       24.75   0.0        0.0   \n",
       "82526          134.0        36.50       13.91   0.0        0.0   \n",
       "82527          141.0        36.40        2.72   0.0        0.0   \n",
       "82528          146.0        36.60        7.66   0.0        0.0   \n",
       "82529          136.0        36.40       10.40   0.0        0.0   \n",
       "82530          141.0        36.30        9.68   0.0        0.0   \n",
       "82531          136.0        36.90       15.53   0.0        0.0   \n",
       "82532          140.0        36.80        8.56   0.0        0.0   \n",
       "82533          134.0        36.40       10.40   0.0        0.0   \n",
       "82534          139.0        36.60        7.14   0.0        0.0   \n",
       "82535          138.0        36.50       10.40   0.0        0.0   \n",
       "82536          138.0        36.60       10.40   0.0        0.0   \n",
       "82537          136.0        37.40        4.22   0.0        0.0   \n",
       "82538          135.0        35.80       17.55   0.0        0.0   \n",
       "82539          138.0        36.30       10.40   0.0        0.0   \n",
       "82540          132.0        36.00       24.40   0.0        0.0   \n",
       "\n",
       "       diabetes_mellitus  hepatic_failure  immunosuppression  leukemia  \\\n",
       "0                    0.0              0.0                0.0       0.0   \n",
       "1                    0.0              0.0                0.0       0.0   \n",
       "2                    0.0              0.0                0.0       0.0   \n",
       "3                    0.0              0.0                0.0       0.0   \n",
       "4                    1.0              0.0                0.0       0.0   \n",
       "5                    0.0              0.0                0.0       0.0   \n",
       "6                    1.0              0.0                0.0       0.0   \n",
       "7                    0.0              0.0                0.0       0.0   \n",
       "8                    0.0              0.0                0.0       0.0   \n",
       "9                    0.0              0.0                0.0       0.0   \n",
       "10                   0.0              0.0                0.0       0.0   \n",
       "11                   0.0              0.0                0.0       0.0   \n",
       "12                   0.0              0.0                0.0       0.0   \n",
       "13                   0.0              0.0                0.0       0.0   \n",
       "14                   0.0              0.0                0.0       0.0   \n",
       "15                   0.0              0.0                0.0       0.0   \n",
       "16                   0.0              0.0                0.0       0.0   \n",
       "17                   0.0              0.0                0.0       0.0   \n",
       "18                   0.0              0.0                0.0       0.0   \n",
       "19                   0.0              0.0                0.0       0.0   \n",
       "20                   0.0              0.0                0.0       0.0   \n",
       "21                   0.0              0.0                0.0       0.0   \n",
       "22                   0.0              0.0                0.0       0.0   \n",
       "23                   0.0              0.0                0.0       0.0   \n",
       "24                   0.0              0.0                0.0       0.0   \n",
       "25                   0.0              1.0                0.0       0.0   \n",
       "26                   0.0              0.0                0.0       0.0   \n",
       "27                   0.0              0.0                0.0       0.0   \n",
       "28                   0.0              0.0                0.0       0.0   \n",
       "29                   0.0              0.0                0.0       0.0   \n",
       "...                  ...              ...                ...       ...   \n",
       "82511                0.0              0.0                0.0       0.0   \n",
       "82512                0.0              0.0                0.0       0.0   \n",
       "82513                0.0              0.0                0.0       0.0   \n",
       "82514                0.0              0.0                0.0       0.0   \n",
       "82515                0.0              0.0                0.0       0.0   \n",
       "82516                1.0              0.0                0.0       0.0   \n",
       "82517                0.0              0.0                0.0       0.0   \n",
       "82518                0.0              0.0                0.0       0.0   \n",
       "82519                0.0              0.0                0.0       0.0   \n",
       "82520                1.0              0.0                0.0       0.0   \n",
       "82521                0.0              0.0                0.0       0.0   \n",
       "82522                1.0              0.0                0.0       0.0   \n",
       "82523                0.0              0.0                0.0       0.0   \n",
       "82524                0.0              0.0                0.0       0.0   \n",
       "82525                0.0              0.0                0.0       0.0   \n",
       "82526                0.0              0.0                0.0       0.0   \n",
       "82527                0.0              0.0                0.0       0.0   \n",
       "82528                0.0              0.0                0.0       0.0   \n",
       "82529                1.0              0.0                0.0       0.0   \n",
       "82530                0.0              0.0                0.0       0.0   \n",
       "82531                1.0              0.0                0.0       0.0   \n",
       "82532                0.0              0.0                0.0       0.0   \n",
       "82533                1.0              0.0                0.0       0.0   \n",
       "82534                0.0              0.0                0.0       0.0   \n",
       "82535                0.0              0.0                0.0       0.0   \n",
       "82536                1.0              0.0                0.0       0.0   \n",
       "82537                0.0              0.0                0.0       0.0   \n",
       "82538                1.0              0.0                0.0       0.0   \n",
       "82539                0.0              0.0                0.0       0.0   \n",
       "82540                0.0              0.0                0.0       0.0   \n",
       "\n",
       "       lymphoma  solid_tumor_with_metastasis  hospital_death  \n",
       "0           0.0                          0.0               0  \n",
       "1           0.0                          0.0               0  \n",
       "2           0.0                          0.0               0  \n",
       "3           0.0                          0.0               0  \n",
       "4           0.0                          0.0               0  \n",
       "5           0.0                          0.0               0  \n",
       "6           0.0                          0.0               0  \n",
       "7           0.0                          0.0               0  \n",
       "8           0.0                          0.0               0  \n",
       "9           0.0                          0.0               0  \n",
       "10          0.0                          0.0               0  \n",
       "11          0.0                          0.0               0  \n",
       "12          0.0                          0.0               0  \n",
       "13          0.0                          0.0               0  \n",
       "14          0.0                          0.0               0  \n",
       "15          0.0                          0.0               0  \n",
       "16          0.0                          0.0               0  \n",
       "17          0.0                          0.0               0  \n",
       "18          0.0                          0.0               0  \n",
       "19          0.0                          0.0               0  \n",
       "20          0.0                          0.0               0  \n",
       "21          0.0                          0.0               0  \n",
       "22          0.0                          0.0               0  \n",
       "23          0.0                          0.0               0  \n",
       "24          0.0                          0.0               0  \n",
       "25          0.0                          0.0               0  \n",
       "26          0.0                          0.0               0  \n",
       "27          0.0                          0.0               0  \n",
       "28          0.0                          0.0               0  \n",
       "29          0.0                          0.0               0  \n",
       "...         ...                          ...             ...  \n",
       "82511       0.0                          0.0               0  \n",
       "82512       0.0                          0.0               0  \n",
       "82513       0.0                          0.0               0  \n",
       "82514       0.0                          0.0               0  \n",
       "82515       0.0                          0.0               0  \n",
       "82516       0.0                          0.0               0  \n",
       "82517       0.0                          0.0               0  \n",
       "82518       0.0                          0.0               0  \n",
       "82519       0.0                          0.0               1  \n",
       "82520       0.0                          0.0               0  \n",
       "82521       0.0                          0.0               0  \n",
       "82522       0.0                          0.0               0  \n",
       "82523       0.0                          0.0               0  \n",
       "82524       0.0                          0.0               1  \n",
       "82525       0.0                          0.0               0  \n",
       "82526       0.0                          0.0               0  \n",
       "82527       0.0                          0.0               0  \n",
       "82528       0.0                          0.0               0  \n",
       "82529       0.0                          0.0               0  \n",
       "82530       0.0                          0.0               0  \n",
       "82531       0.0                          0.0               0  \n",
       "82532       0.0                          0.0               0  \n",
       "82533       0.0                          0.0               0  \n",
       "82534       0.0                          0.0               0  \n",
       "82535       0.0                          0.0               0  \n",
       "82536       0.0                          1.0               0  \n",
       "82537       0.0                          0.0               0  \n",
       "82538       0.0                          0.0               0  \n",
       "82539       0.0                          0.0               0  \n",
       "82540       0.0                          0.0               0  \n",
       "\n",
       "[82541 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive  Naive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Naives 0: Positive-> 0.5517676767676768\t Negative-> 0.8920047732696897\n",
      "Recall Naives 1: Positive-> 0.5441919191919192\t Negative-> 0.8788782816229117\n",
      "Recall Naives 2: Positive-> 0.6426767676767676\t Negative-> 0.8690930787589499\n",
      "Recall Naives 3: Positive-> 0.6060606060606061\t Negative-> 0.8507159904534606\n",
      "Recall Naives 4: Positive-> 0.6502525252525253\t Negative-> 0.8332935560859188\n",
      "Recall Naives 5: Positive-> 0.5524652338811631\t Negative-> 0.8853221957040572\n",
      "Recall Naives 6: Positive-> 0.5802781289506953\t Negative-> 0.8729116945107399\n",
      "Recall Naives 7: Positive-> 0.5916561314791403\t Negative-> 0.8805489260143198\n",
      "Recall Naives 8: Positive-> 0.5600505689001264\t Negative-> 0.8812507459124\n",
      "Recall Naives 9: Positive-> 0.5815423514538559\t Negative-> 0.8606038906790786\n"
     ]
    }
   ],
   "source": [
    "# fuente  -> https://machinelearningmastery.com/naive-classifiers-imbalanced-classification-metrics/\n",
    "model_NC = []\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    model =  GaussianNB()\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model, path + 'NC'+ str(i) +'.pkl') \n",
    "    model_NC.append(model)\n",
    "    predict = model.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    result = classification_report(test_folds[i][\"hospital_death\"], predict, output_dict=True)\n",
    "    recall = result[\"1\"][\"recall\"]\n",
    "    recalln = result[\"0\"][\"recall\"]\n",
    "    print(\"Recall Naives \" + str(i) + \": Positive-> \" + str(recall) +\"\\t Negative-> \" + str(recalln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive  RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall RF 0: Positive-> 0.7045454545454546\t Negative-> 0.8556085918854416\n",
      "Recall RF 1: Positive-> 0.7411616161616161\t Negative-> 0.7910501193317423\n",
      "Recall RF 2: Positive-> 0.76010101010101\t Negative-> 0.8014319809069212\n",
      "Recall RF 3: Positive-> 0.7904040404040404\t Negative-> 0.7608591885441528\n",
      "Recall RF 4: Positive-> 0.7828282828282829\t Negative-> 0.7786396181384249\n",
      "Recall RF 5: Positive-> 0.7269279393173198\t Negative-> 0.8176610978520287\n",
      "Recall RF 6: Positive-> 0.7168141592920354\t Negative-> 0.8122911694510739\n",
      "Recall RF 7: Positive-> 0.7243994943109987\t Negative-> 0.7976133651551313\n",
      "Recall RF 8: Positive-> 0.706700379266751\t Negative-> 0.8045112781954887\n",
      "Recall RF 9: Positive-> 0.7269279393173198\t Negative-> 0.8024823964673589\n"
     ]
    }
   ],
   "source": [
    "model_RF = []\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    model = RandomForestClassifier(max_depth=3, random_state=0, class_weight='balanced', n_estimators=50)\n",
    "    d = (train_folds[i]).drop(columns=[\"hospital_death\"])\n",
    "    model.fit(d, train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model, path + 'RF'+ str(i) +'.pkl') \n",
    "    model_RF.append(model)\n",
    "    predict = model.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    result = classification_report(test_folds[i][\"hospital_death\"], predict, output_dict=True)\n",
    "    recall = result[\"1\"][\"recall\"]\n",
    "    recalln = result[\"0\"][\"recall\"]\n",
    "    print(\"Recall RF \" + str(i) + \": Positive-> \" + str(recall) +\"\\t Negative-> \" + str(recalln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive  SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall SVM 0: Positive-> 0.7222222222222222\t Negative-> 0.8305489260143198\n",
      "Recall SVM 1: Positive-> 0.7626262626262627\t Negative-> 0.7978520286396181\n",
      "Recall SVM 2: Positive-> 0.8169191919191919\t Negative-> 0.7606205250596658\n",
      "Recall SVM 3: Positive-> 0.7866161616161617\t Negative-> 0.7513126491646778\n",
      "Recall SVM 4: Positive-> 0.7916666666666666\t Negative-> 0.7523866348448688\n",
      "Recall SVM 5: Positive-> 0.7395701643489254\t Negative-> 0.8140811455847256\n",
      "Recall SVM 6: Positive-> 0.7610619469026548\t Negative-> 0.789618138424821\n",
      "Recall SVM 7: Positive-> 0.7585335018963337\t Negative-> 0.778400954653938\n",
      "Recall SVM 8: Positive-> 0.7256637168141593\t Negative-> 0.789234992242511\n",
      "Recall SVM 9: Positive-> 0.7926675094816688\t Negative-> 0.7511636233440745\n"
     ]
    }
   ],
   "source": [
    "#fuente ->  https://machinelearningmastery.com/cost-sensitive-svm-for-imbalanced-classification/\n",
    "model_SVM = []\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    model = SVC(gamma='scale', class_weight='balanced')\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model, path + 'SVM'+ str(i) +'.pkl') \n",
    "    model_SVM.append(model)\n",
    "    predict = model.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    result = classification_report(test_folds[i][\"hospital_death\"], predict, output_dict=True)\n",
    "    recall = result[\"1\"][\"recall\"]\n",
    "    recalln = result[\"0\"][\"recall\"]\n",
    "    print(\"Recall SVM \" + str(i) + \": Positive-> \" + str(recall) +\"\\t Negative-> \" + str(recalln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-sensitive  LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall LR 0: Positive-> 0.6893939393939394\t Negative-> 0.8305489260143198\n",
      "Recall LR 1: Positive-> 0.7184343434343434\t Negative-> 0.802744630071599\n",
      "Recall LR 2: Positive-> 0.8131313131313131\t Negative-> 0.7443914081145585\n",
      "Recall LR 3: Positive-> 0.7676767676767676\t Negative-> 0.7402147971360382\n",
      "Recall LR 4: Positive-> 0.7790404040404041\t Negative-> 0.7522673031026254\n",
      "Recall LR 5: Positive-> 0.7029077117572693\t Negative-> 0.815035799522673\n",
      "Recall LR 6: Positive-> 0.718078381795196\t Negative-> 0.8038186157517899\n",
      "Recall LR 7: Positive-> 0.7458912768647282\t Negative-> 0.8009546539379475\n",
      "Recall LR 8: Positive-> 0.6978508217446271\t Negative-> 0.7912638739706409\n",
      "Recall LR 9: Positive-> 0.7737041719342604\t Negative-> 0.7385129490392648\n"
     ]
    }
   ],
   "source": [
    "# fuente -> https://machinelearningmastery.com/cost-sensitive-logistic-regression/\n",
    "model_LR = []\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
    "for i in range(len(train_folds)):\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model,path +  'LR'+ str(i) +'.pkl')\n",
    "    model_LR.append(model)\n",
    "    predict = model.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    result = classification_report(test_folds[i][\"hospital_death\"], predict, output_dict=True)\n",
    "    recall = result[\"1\"][\"recall\"]\n",
    "    recalln = result[\"0\"][\"recall\"]\n",
    "    print(\"Recall LR \" + str(i) + \": Positive-> \" + str(recall) +\"\\t Negative-> \" + str(recalln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall TC 0: Positive-> 0.2828282828282828\t Negative-> 0.9478520286396181\n",
      "Recall TC 1: Positive-> 0.30934343434343436\t Negative-> 0.9326968973747016\n",
      "Recall TC 2: Positive-> 0.3383838383838384\t Negative-> 0.9353221957040573\n",
      "Recall TC 3: Positive-> 0.3522727272727273\t Negative-> 0.9278042959427207\n",
      "Recall TC 4: Positive-> 0.3055555555555556\t Negative-> 0.9247016706443915\n",
      "Recall TC 5: Positive-> 0.3147914032869785\t Negative-> 0.9353221957040573\n",
      "Recall TC 6: Positive-> 0.27560050568900124\t Negative-> 0.9445107398568019\n",
      "Recall TC 7: Positive-> 0.26548672566371684\t Negative-> 0.9313842482100239\n",
      "Recall TC 8: Positive-> 0.2857142857142857\t Negative-> 0.9393722401241198\n",
      "Recall TC 9: Positive-> 0.32616940581542353\t Negative-> 0.9336436328917532\n"
     ]
    }
   ],
   "source": [
    "model_DT= []\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    model = DecisionTreeClassifier(class_weight='balanced')\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model, path +  'DT'+ str(i) +'.pkl') \n",
    "    model_DT.append(model)\n",
    "    predict = model.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    result = classification_report(test_folds[i][\"hospital_death\"], predict, output_dict=True)\n",
    "    recall = result[\"1\"][\"recall\"]\n",
    "    recalln = result[\"0\"][\"recall\"]\n",
    "    print(\"Recall TC \" + str(i) + \": Positive-> \" + str(recall) +\"\\t Negative-> \" + str(recalln))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Knn 0: Positive-> 0.05176767676767677\t Negative-> 0.9992840095465394\n",
      "Recall Knn 1: Positive-> 0.03409090909090909\t Negative-> 0.9992840095465394\n",
      "Recall Knn 2: Positive-> 0.016414141414141416\t Negative-> 1.0\n",
      "Recall Knn 3: Positive-> 0.05555555555555555\t Negative-> 0.9992840095465394\n",
      "Recall Knn 4: Positive-> 0.025252525252525252\t Negative-> 0.999164677804296\n",
      "Recall Knn 5: Positive-> 0.05562579013906448\t Negative-> 0.9989260143198091\n",
      "Recall Knn 6: Positive-> 0.051833122629582805\t Negative-> 0.9985680190930788\n",
      "Recall Knn 7: Positive-> 0.0316055625790139\t Negative-> 0.9992840095465394\n",
      "Recall Knn 8: Positive-> 0.0316055625790139\t Negative-> 0.9995226160639694\n",
      "Recall Knn 9: Positive-> 0.0695322376738306\t Negative-> 0.998687194175916\n"
     ]
    }
   ],
   "source": [
    "model_KKN = []\n",
    "recall_KKN = []\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    model = KNeighborsClassifier(n_neighbors=30)\n",
    "    n_neighbors = range(1, 10, 3)\n",
    "    weights = ['uniform', 'distance']\n",
    "    metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "    #grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "    #grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='recall',error_score=0)\n",
    "    #grid_result = grid_search.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    model_KKN.append(model)\n",
    "    joblib.dump(model,path +   'KNN'+ str(i) +'.pkl') \n",
    "    predict = model.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    result = classification_report(test_folds[i][\"hospital_death\"], predict, output_dict=True)\n",
    "    recall = result[\"1\"][\"recall\"]\n",
    "    recalln = result[\"0\"][\"recall\"]\n",
    "    print(\"Recall Knn \" + str(i) + \": Positive-> \" + str(recall) +\"\\t Negative-> \" + str(recalln))\n",
    "    # summarize results\n",
    "    \"\"\"\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SGB = []\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model, path + 'SGB'+ str(i) +'.pkl') \n",
    "    model_SGB.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost-Sensitive Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# https://machinelearningmastery.com/cost-sensitive-neural-network-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def create_model(optimizer='adam', neurons=80):\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(180, input_dim=15, activation='relu'))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /media/mdleiton/Respaldo/repositorios/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Recall 0 fold: 0.111111\n",
      "Best: 0.915909 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915896 (0.008760) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.915909 (0.008865) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 1 fold: 0.070707\n",
      "Best: 0.916030 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915884 (0.008820) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.916030 (0.008889) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 2 fold: 0.089646\n",
      "Best: 0.915896 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915448 (0.008321) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.915896 (0.009117) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 3 fold: 0.080910\n",
      "Best: 0.916006 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915885 (0.007049) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.916006 (0.007303) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 4 fold: 0.142857\n",
      "Best: 0.915691 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915582 (0.010326) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.915691 (0.009908) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 5 fold: 0.065740\n",
      "Best: 0.916006 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915788 (0.010035) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.916006 (0.010105) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 6 fold: 0.068268\n",
      "Best: 0.915679 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915594 (0.004601) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.915679 (0.004311) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 7 fold: 0.042984\n",
      "Best: 0.915922 using {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.915922 (0.007350) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.915813 (0.007088) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 8 fold: 0.060606\n",
      "Best: 0.916019 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915861 (0.007017) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.916019 (0.007153) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "Recall 9 fold: 0.054293\n",
      "Best: 0.916079 using {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n",
      "0.915982 (0.006793) with: {'batch_size': 2000, 'neurons': 60, 'epochs': 20}\n",
      "0.916079 (0.006889) with: {'batch_size': 2000, 'neurons': 80, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "model_NR = []\n",
    "recall_NR = []\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "batch_size = [2000]\n",
    "neurons = [60,80]\n",
    "epochs = [20]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "for i in range(len(train_folds)):\n",
    "    grid_result = grid.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"], class_weight='balanced')\n",
    "    # summarize results\n",
    "    predict = grid_result.predict(test_folds[i].drop(columns=[\"hospital_death\"]))\n",
    "    recall = recall_score(test_folds[i][\"hospital_death\"], predict, average='binary')\n",
    "    print('Recall %d fold: %f' % (i , recall))\n",
    "    recall_NR.append(recall)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVM = []\n",
    "for i in range(len(train_folds)):\n",
    "    model = joblib.load(path + 'SVM' + str(i) + '.pkl')\n",
    "    model_SVM.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SC = []\n",
    "\n",
    "for i in range(len(train_folds)):\n",
    "    estimators = [ ('nv', model_NC[i]), ('rf', model_RF[i]), ('svm',model_SVM[i]), ('lr',model_LR[i]), ('dt',model_DT[i]), ('knn',model_KKN[i]), ('sgb',model_SGB[i])]\n",
    "    model = clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "    model.fit(train_folds[i].drop(columns=[\"hospital_death\"]), train_folds[i][\"hospital_death\"])\n",
    "    joblib.dump(model,path +  'stack'+ str(i) +'.pkl') \n",
    "    model_SC.append(model)\n",
    "    print(\"Modelo stack: \" + str(i) + \"guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
